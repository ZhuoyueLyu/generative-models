{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "CSC412_BiGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZXK8aCBc4bV"
      },
      "source": [
        "!nvidia-smi # Check GPU type, Tesla T4 (good) and P100 (best) are better"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ma6dhPC7cY7U",
        "outputId": "08521f3d-8cac-43ab-ef29-888c3c009e8a"
      },
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGKeRBruxmuV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0382dd0a-fd0c-4830-e731-210bc5751cfe"
      },
      "source": [
        "# clone the speech dataset\n",
        "%cd drive/My Drive/Courses/CSC412\n",
        "# !git clone --recursive https://github.com/Jakobovski/free-spoken-digit-dataset.git # clone the dataset into local"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Courses/CSC412\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIascSZUcSE_"
      },
      "source": [
        "import os, sys, json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile as wav\n",
        "import torch\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from __future__ import division, print_function\n",
        "from IPython import display\n",
        "from shutil import copyfile\n",
        "from scipy.spatial import distance as dist\n",
        "from scipy import stats\n",
        "from sklearn import preprocessing, manifold, decomposition, random_projection, neighbors, metrics, linear_model\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.layers import *\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "from keras import losses\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "sns.set_context('talk', font_scale=1.2)\n",
        "np.random.seed(412)\n",
        "tf.random.set_seed(412)\n",
        "base_path = \"/content/drive/MyDrive/Courses/CSC412/free-spoken-digit-dataset/\"\n",
        "\n",
        "# from tensorflow.examples.tutorials.mnist import input_data\n",
        "# mnist = input_data.read_data_sets('MNIST_data', one_hot=False)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ19HF2KqyP4"
      },
      "source": [
        "# Helper functions\n",
        "def wav_to_spectrogram(audio_path, save_path, spectrogram_dimensions=(64, 64), noverlap=16, cmap='gray_r'):\n",
        "    \"\"\" Creates a spectrogram of a wav file.\n",
        "\n",
        "    :param audio_path: path of wav file\n",
        "    :param save_path:  path of spectrogram to save\n",
        "    :param spectrogram_dimensions: number of pixels the spectrogram should be. Defaults (64,64)\n",
        "    :param noverlap: See http://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.spectrogram.html\n",
        "    :param cmap: the color scheme to use for the spectrogram. Defaults to 'gray_r'\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    sample_rate, samples = wav.read(audio_path)\n",
        "\n",
        "    fig = plt.figure()\n",
        "    fig.set_size_inches((spectrogram_dimensions[0]/fig.get_dpi(), spectrogram_dimensions[1]/fig.get_dpi()))\n",
        "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
        "    ax.set_axis_off()\n",
        "    fig.add_axes(ax)\n",
        "    ax.specgram(samples, cmap=cmap, Fs=2, noverlap=noverlap)\n",
        "    ax.xaxis.set_major_locator(plt.NullLocator())\n",
        "    ax.yaxis.set_major_locator(plt.NullLocator())\n",
        "    fig.savefig(save_path, bbox_inches=\"tight\", pad_inches=0)\n",
        "\n",
        "\n",
        "def dir_to_spectrogram(audio_dir, spectrogram_dir, spectrogram_dimensions=(64, 64), noverlap=16, cmap='gray_r'):\n",
        "    \"\"\" Creates spectrograms of all the audio files in a dir\n",
        "\n",
        "    :param audio_dir: path of directory with audio files\n",
        "    :param spectrogram_dir: path to save spectrograms\n",
        "    :param spectrogram_dimensions: tuple specifying the dimensions in pixes of the created spectrogram. default:(64,64)\n",
        "    :param noverlap: See http://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.spectrogram.html\n",
        "    :param cmap: the color scheme to use for the spectrogram. Defaults to 'gray_r'\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    file_names = [f for f in listdir(audio_dir) if isfile(join(audio_dir, f)) and '.wav' in f]\n",
        "\n",
        "    for file_name in file_names:\n",
        "        print(file_name)\n",
        "        audio_path = audio_dir + file_name\n",
        "        spectogram_path = spectrogram_dir + file_name.replace('.wav', '.png')\n",
        "        wav_to_spectrogram(audio_path, spectogram_path, spectrogram_dimensions=spectrogram_dimensions, noverlap=noverlap, cmap=cmap)\n",
        "\n",
        "\n",
        "def sample_latent_space(model, n_dims, n=20, sample_type='uniform', scale=True):\n",
        "    '''Sample the latent space of n_dims, \n",
        "    then generate data (images) using model to organize generated \n",
        "    data (images) into a squared canvas for plotting.\n",
        "    model: need to have `generate` method\n",
        "    n_dims: the dimension of the latent space\n",
        "    n: number of images along the canvas\n",
        "    '''\n",
        "    dim = 64\n",
        "    canvas = np.empty((dim*n, dim*n))\n",
        "    if sample_type == 'uniform':\n",
        "        zs_mu = np.random.uniform(-3, 3, n_dims * n**2)\n",
        "    elif sample_type == 'normal':\n",
        "        zs_mu = np.random.randn(n_dims * n**2)\n",
        "    zs_mu = zs_mu.reshape(n**2, n_dims)\n",
        "    \n",
        "    xs_gen = model.generate(zs_mu)\n",
        "    c = 0\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            x = xs_gen[c]\n",
        "            if scale:\n",
        "                x = preprocessing.minmax_scale(x.T).T\n",
        "            canvas[(n-i-1)*dim:(n-i)*dim, j*dim:(j+1)*dim] = x.reshape(dim, dim)\n",
        "            c += 1\n",
        "    return canvas"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR5X0Cfbqz33"
      },
      "source": [
        "## Creat the directory for spectrograms\n",
        "# audio_dir = \"/content/drive/MyDrive/Courses/CSC412/free-spoken-digit-dataset/recordings/\"\n",
        "# spectrogram_dir = \"/content/drive/MyDrive/Courses/CSC412/free-spoken-digit-dataset/spectrograms/\"\n",
        "# dir_to_spectrogram(audio_dir, spectrogram_dir)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_WDAJQrqhBw"
      },
      "source": [
        "class BiGAN():\n",
        "    def __init__(self, g_n_layers=[784, 10], d_n_layers=[100, 10], learning_rate=0.001, build_model=True):\n",
        "        '''\n",
        "        BiGAN: Bidirectional Generative Adversarial Network\n",
        "        g_n_layers(list): number of neurons for generator network, \n",
        "            the reverse is for the encoder network, the first element should be \n",
        "            the input dim, last element should be the latent dim.\n",
        "        d_n_layers(list): number of hidden units, the first element is the first hidden layer, \n",
        "            the input dim will be g_n_layers[0] + g_n_layers[-1].\n",
        "        '''\n",
        "        self.g_n_layers = g_n_layers\n",
        "        self.d_n_layers = d_n_layers\n",
        "        self.input_shape = g_n_layers[0]\n",
        "        self.latent_dim = g_n_layers[-1]\n",
        "        self.learning_rate = learning_rate\n",
        "        self.params = {\n",
        "            'g_n_layers': g_n_layers,\n",
        "            'd_n_layers': d_n_layers,\n",
        "            'learning_rate': learning_rate\n",
        "        }\n",
        "        if build_model:\n",
        "            self.build_gan()\n",
        "\n",
        "    def build_gan(self):\n",
        "        optimizer = Adam(self.learning_rate, 0.5)\n",
        "\n",
        "        # Build and compile the discriminator\n",
        "        self.discriminator = self.build_discriminator()\n",
        "        self.discriminator.compile(loss=['binary_crossentropy'],\n",
        "            optimizer=optimizer,\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "        # Build the generator\n",
        "        self.generator = self.build_generator()\n",
        "\n",
        "        # Build the encoder\n",
        "        self.encoder = self.build_encoder()\n",
        "\n",
        "        # The part of the bigan that trains the discriminator and encoder\n",
        "        self.discriminator.trainable = False\n",
        "\n",
        "        # Generate image from sampled noise\n",
        "        z = Input(shape=(self.latent_dim, ))\n",
        "        img_ = self.generator(z)\n",
        "\n",
        "        # Encode image\n",
        "        img = Input(shape=(self.input_shape, ))\n",
        "        z_ = self.encoder(img)\n",
        "\n",
        "        # Latent -> img is fake, and img -> latent is valid\n",
        "        fake = self.discriminator([z, img_])\n",
        "        valid = self.discriminator([z_, img])\n",
        "\n",
        "        # Set up and compile the combined model\n",
        "        # Trains generator to fool the discriminator\n",
        "        self.bigan_generator = Model([z, img], [fake, valid])\n",
        "        self.bigan_generator.compile(loss=['binary_crossentropy', 'binary_crossentropy'],\n",
        "            optimizer=optimizer)\n",
        "\n",
        "\n",
        "    def build_encoder(self):\n",
        "        '''Encoder model encodes input to latent dim: E(x) = z.'''\n",
        "        model = Sequential()\n",
        "\n",
        "        for i, n_layer in enumerate(self.g_n_layers[1:]):\n",
        "            if i == 0:\n",
        "                model.add(Dense(n_layer, input_dim=self.input_shape))\n",
        "            else:\n",
        "                model.add(Dense(n_layer))\n",
        "            model.add(LeakyReLU(alpha=0.2))\n",
        "            model.add(BatchNormalization(momentum=0.8))\n",
        "        \n",
        "        model.summary()\n",
        "\n",
        "        img = Input(shape=(self.input_shape, ))\n",
        "        z = model(img)\n",
        "\n",
        "        return Model(img, z)\n",
        "\n",
        "    def build_generator(self):\n",
        "        model = Sequential()\n",
        "        for i, n_layer in enumerate(self.g_n_layers[::-1][1:]):\n",
        "            if i == 0:\n",
        "                model.add(Dense(n_layer, input_dim=self.latent_dim))\n",
        "                model.add(LeakyReLU(alpha=0.2))\n",
        "                model.add(BatchNormalization(momentum=0.8))\n",
        "            elif i == len(self.g_n_layers) - 2: # last layer\n",
        "                model.add(Dense(n_layer, activation='tanh'))\n",
        "            else:\n",
        "                model.add(Dense(n_layer)) \n",
        "                model.add(LeakyReLU(alpha=0.2))\n",
        "                model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        z = Input(shape=(self.latent_dim,))\n",
        "        gen_img = model(z)\n",
        "\n",
        "        return Model(z, gen_img)\n",
        "\n",
        "    def build_discriminator(self):\n",
        "\n",
        "        z = Input(shape=(self.latent_dim, ))\n",
        "        img = Input(shape=(self.input_shape, ))\n",
        "        d_in = concatenate([z, img])\n",
        "\n",
        "        for i, n_layer in enumerate(self.d_n_layers):\n",
        "            if i == 0:\n",
        "                model = Dense(n_layer)(d_in)\n",
        "                model = LeakyReLU(alpha=0.2)(model)\n",
        "                model = Dropout(0.5)(model)\n",
        "\n",
        "            else:\n",
        "                model = Dense(n_layer)(model)        \n",
        "                model = LeakyReLU(alpha=0.2)(model)\n",
        "                model = Dropout(0.5)(model)\n",
        "        \n",
        "        validity = Dense(1, activation=\"sigmoid\")(model)\n",
        "\n",
        "        return Model([z, img], validity)\n",
        "\n",
        "    def partial_fit(self, x_batch):\n",
        "        '''Train G, E, D using a batch of data.'''\n",
        "        # Adversarial ground truths\n",
        "        # batch_size = x_batch.shape[0]\n",
        "        batch_size = len(x_batch)\n",
        "        valid = np.ones((batch_size, 1))\n",
        "        fake = np.zeros((batch_size, 1))\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        # Sample noise and generate img\n",
        "        z = np.random.normal(size=(batch_size, self.latent_dim))\n",
        "        x_batch_gen = self.generator.predict(z)\n",
        "\n",
        "        # Select a random batch of images and encode\n",
        "        z_ = self.encoder.predict(x_batch)\n",
        "\n",
        "        # Train the discriminator (x_batch -> z_ is valid, z -> x_batch_gen is fake)\n",
        "        d_loss_real = self.discriminator.train_on_batch([z_, x_batch], valid)\n",
        "        d_loss_fake = self.discriminator.train_on_batch([z, x_batch_gen], fake)\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "        # ---------------------\n",
        "        #  Train Generator\n",
        "        # ---------------------\n",
        "\n",
        "        # Train the generator (z -> x_batch is valid and x_batch -> z is is invalid)\n",
        "        g_loss = self.bigan_generator.train_on_batch([z, x_batch], [valid, fake])\n",
        "        \n",
        "        accuracy = d_loss[1]\n",
        "        # scalers for loss and accuracy from the discriminator\n",
        "        return d_loss[0], accuracy, g_loss[0]\n",
        "\n",
        "    def transform(self, X):\n",
        "        '''Run encoder to get the latent embedding: z = E(x).'''\n",
        "        return self.encoder.predict(X)\n",
        "\n",
        "    def generate(self, z = None):\n",
        "        if z is None:\n",
        "            z = np.random.normal(size=[1, self.latent_dim])\n",
        "        return self.generator.predict(z)\n",
        "\n",
        "    def save(self, path):\n",
        "        '''Save trained models to files'''\n",
        "        self.generator.save(os.path.join(path, \"generator.h5\"))\n",
        "        self.discriminator.save(os.path.join(path, \"discriminator.h5\"))\n",
        "        self.encoder.save(os.path.join(path, \"encoder.h5\"))\n",
        "        self.bigan_generator.save(os.path.join(path, \"bigan_generator.h5\"))\n",
        "        json.dump( self.params, open(os.path.join(path, 'params.json'), 'w') ) \n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, path):\n",
        "        params = json.load(open(os.path.join(path, 'params.json'), 'r'))\n",
        "        params['build_model'] = False\n",
        "        gan = cls(**params)\n",
        "        gan.generator = load_model(os.path.join(path, \"generator.h5\"))\n",
        "        gan.discriminator = load_model(os.path.join(path, \"discriminator.h5\"))\n",
        "        gan.encoder = load_model(os.path.join(path, \"encoder.h5\"))\n",
        "        gan.bigan_generator = load_model(os.path.join(path, \"bigan_generator.h5\"))\n",
        "        return gan\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDkG4AcE6AiQ"
      },
      "source": [
        "# train-test split\n",
        "# As per README:\n",
        "# All files of iteration 0-4 move to testing-spectrograms\n",
        "# All files of iteration 5-49 move to training-spectrograms\n",
        "\n",
        "def separate(base):\n",
        "    for filename in os.listdir(base + \"spectrograms/\" ):\n",
        "        first_split = filename.rsplit(\"_\", 1)[1]\n",
        "        second_split = first_split.rsplit(\".\", 1)[0]\n",
        "        if int(second_split) <= 4:\n",
        "            copyfile(base + \"spectrograms/\" + filename, base + \"testing-spectrograms\" + \"/\" + filename)\n",
        "        else:\n",
        "            copyfile(base + \"spectrograms/\" + filename, base + \"training-spectrograms\" + \"/\" + filename)\n",
        "\n",
        "\n",
        "# separate(base_path)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLJFSS6Ntkoc"
      },
      "source": [
        "class SpeechData(Dataset):\n",
        "  def __init__(self, data_path):\n",
        "    self.path = data_path\n",
        "    self.images = []\n",
        "    self.labels = []\n",
        "    for filename in os.listdir(data_path):\n",
        "      label = int(filename[0])\n",
        "      image = [plt.imread(data_path+\"/\"+filename)[:,:,0]]\n",
        "    #   self.images.append(tf.convert_to_tensor(image))\n",
        "    #   self.labels.append(tf.convert_to_tensor(label))\n",
        "      self.images.append(image)\n",
        "      self.labels.append(label)\n",
        "      # self.images.append(np.array(image).flatten())\n",
        "      # self.labels.append(np.array(label).flatten())\n",
        "      self.len = len(self.images)\n",
        "      # print(filename)\n",
        "\n",
        "  def next_batch(self, step, batch_size):\n",
        "    start = step * batch_size\n",
        "    end = min(self.len, (step + 1) * batch_size)\n",
        "    return np.array(self.images[start:end]), np.array(self.labels[start:end])\n",
        "    # return self.images[start:end], self.labels[start:end]\n",
        "    # return tf.convert_to_tensor(self.images[start:end]), tf.convert_to_tensor(self.labels[start:end])\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.len"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "8gT2EzuIcSFO"
      },
      "source": [
        "batch_size = 100\n",
        "learning_rate=0.001\n",
        "image_dim = 64 # each image is 64 * 64 dimension\n",
        "n_samples = 2700 # total number of samples is 3000, 5 * 10 * 6 are used as test set\n",
        "\n",
        "# model\n",
        "bigan = BiGAN(g_n_layers=[image_dim * image_dim, 500, 500, 20],\n",
        "            #   d_n_layers=[1000, 1000, 1000],\n",
        "            d_n_layers=[1000, 1000, 100],\n",
        "              learning_rate=learning_rate)\n",
        "\n",
        "# data\n",
        "train_dataset = SpeechData(base_path + \"training-spectrograms/\")\n",
        "# test_dataset = SpeechData(base_path + \"testing-spectrograms/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9peW2MbSzvSs"
      },
      "source": [
        "# import tensorflow_datasets as tfds\n",
        "# # Construct a tf.data.Dataset\n",
        "# mnist = tfds.load(name=\"mnist\", split=tfds.Split.TRAIN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "jADDyvbRcSFP"
      },
      "source": [
        "# Training loop\n",
        "d_losses = []\n",
        "accs = []\n",
        "g_losses = []\n",
        "training_epochs = 10\n",
        "# display_step = 10\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "    total_batch = int(n_samples / batch_size)\n",
        "    # Loop over all batches\n",
        "    for i in range(total_batch):\n",
        "        batch_xs, _ = train_dataset.next_batch(i, batch_size)\n",
        "        # print(batch_xs.shape)\n",
        "        # Fit training using batch data\n",
        "        d_loss, acc, g_loss = bigan.partial_fit(batch_xs)\n",
        "        # Display logs per epoch step\n",
        "        # if epoch % display_step == 0:\n",
        "    print (\"Epoch %d: D loss = %.4f, G loss = %.4f, D accuracy = %.4f \"% (epoch+1, d_loss, g_loss, acc))\n",
        "    \n",
        "    d_losses.append(d_loss)\n",
        "    accs.append(acc)\n",
        "    g_losses.append(g_loss)\n",
        "    \n",
        "    canvas = sample_latent_space(bigan, bigan.latent_dim, sample_type='uniform')\n",
        "    fig, ax = plt.subplots(figsize=(10,10))\n",
        "    ax.imshow(canvas, origin=\"upper\", cmap=\"gray\")\n",
        "    ax.set_axis_off()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ty6NtUmcSFQ"
      },
      "source": [
        "# !mkdir -p trained_models/bigan_100\n",
        "!mkdir -p trained_models/bigan_1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVyqFIuscSFR"
      },
      "source": [
        "# bigan.save('trained_models/bigan_100/')\n",
        "bigan.save('trained_models/bigan_1000/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDQA9wT-cSFR"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(d_losses, label='Discriminator loss')\n",
        "ax.plot(g_losses, label='Generator loss')\n",
        "ax.legend(loc='best')\n",
        "ax.set_xlabel('Epochs')\n",
        "ax.set_ylabel('Loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ob00sqE1cSFR"
      },
      "source": [
        "x_gen = bigan.generate()\n",
        "x_gen.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PflXhoCcSFR"
      },
      "source": [
        "# display_mnist_image(x_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAKsDk74cSFS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}